{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shlex\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "\n",
    "CLIMB_FIELDS = ['id', 'name', 'rating', 'type', 'location', 'url',\n",
    "                'location_url']\n",
    "PARENT_DIR = \"../data/climb_data/{}\"\n",
    "MY_RATINGS = PARENT_DIR.format(\"my_ratings.csv\")\n",
    "REVIEWS = PARENT_DIR.format(\"reviews.csv\")\n",
    "CLIMBS = PARENT_DIR.format(\"climbs.csv\")\n",
    "\n",
    "def parse_my_ratings(line):\n",
    "    \"\"\"                                                                                                                                                                                                                                                                    \n",
    "    climb_id, user_id, rating                                                                                                                                                                                                                                              \n",
    "    \"\"\"\n",
    "    vals = line.split(\",\")\n",
    "    return (int(vals[1]), int(vals[0]), int(vals[2]))\n",
    "\n",
    "def parse_ratings(line):\n",
    "    vals = line.split(\",\")\n",
    "    return (int(vals[0]), (int(vals[2]), int(vals[1]), int(vals[3])))\n",
    "\n",
    "def parse_climb(line):\n",
    "    vals = line.split(\",\")\n",
    "    climbs_dict = dict(zip(CLIMB_FIELDS[1:], vals[1:]))\n",
    "    climbs_dict['id'] = line.split(\",\")[0]\n",
    "    return climbs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_ratings = sc.textFile(MY_RATINGS).map(parse_my_ratings)\n",
    "ratings = sc.textFile(REVIEWS).map(parse_ratings)\n",
    "climbs = sc.textFile(CLIMBS).map(parse_climb)\n",
    "max_ratings = ratings.count()\n",
    "my_ratings.take(5)\n",
    "climbs_dict = {int(climb['id']): climb for climb in climbs.collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    ds = data.map(lambda x: (x[0], x[1]))\n",
    "    predictions = model.predictAll(ds)\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numPartitions = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = ratings.values().union(my_ratings).repartition(numPartitions).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8).values().repartition(numPartitions).cache()\n",
    "print \"VALIDATION: {}\".format(validation.take(5))\n",
    "test = ratings.filter(lambda x: x[0] >  8).values().repartition(numPartitions).cache()\n",
    "print \"TEST: {}\".format(test.take(5))\n",
    "numValidation = validation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranks = [8, 12]\n",
    "lambdas = [0.1, 10.0]\n",
    "numIters = [10, 20]\n",
    "\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1\n",
    "\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "   model = ALS.train(training, rank, numIter, lmbda)\n",
    "   validationRmse = computeRmse(model, validation, numValidation)\n",
    "   print (\"RMSE (validation) = {} for the model trained with \".format(validationRmse),\n",
    "       \"rank = {}, lambda = {}, and numIter = {}.\".format(rank, lmbda, numIter))\n",
    "   if (validationRmse < bestValidationRmse):\n",
    "       bestModel = model\n",
    "       bestValidationRmse = validationRmse\n",
    "       bestRank = rank\n",
    "       bestLambda = lmbda\n",
    "       bestNumIter = numIter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_rated = [rating[2] for rating in my_ratings.collect()]\n",
    "candidate_climbs = sc.parallelize([climb for climb in climbs_dict.keys()])\n",
    "candidate_climbs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = bestModel.predictAll(candidate_climbs.map(lambda row: (0, row))).collect()\n",
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print recommendations[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, recommendation in enumerate(recommendations):\n",
    "    climb = climbs_dict[recommendation[1]]\n",
    "    print \"{}: {} {} - {}\".format(index, climb['id'], climb['name'], recommendation[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
